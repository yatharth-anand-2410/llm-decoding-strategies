{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Repetition Penalties\n",
    "\n",
    "We've covered Temperature, Top-K, and Top-P. These manipulate the probabilities of our tokens globally.\n",
    "\n",
    "However, LLMs still suffer from a known issue: they can get stuck in repetitive loops. If a model generates the word \"dog\" once, it becomes statistically more likely to generate \"dog\" again. This can spiral into an infinite loop.\n",
    "\n",
    "To solve this, we can introduce **Repetition Penalties**. These are applied dynamically to the logits of tokens *that have already appeared* in the generated sequence.\n",
    "\n",
    "There are two main types:\n",
    "1. **Frequency Penalty**: Penalizes a token proportional to *how many times* it has appeared.\n",
    "2. **Presence Penalty**: Penalizes a token if it has appeared *at all*, encouraging the model to introduce completely new topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146ed3141c594e60ad327f820973d724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/290 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 896)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2Attention(\n",
       "          (q_proj): Linear(in_features=896, out_features=896, bias=True)\n",
       "          (k_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (v_proj): Linear(in_features=896, out_features=128, bias=True)\n",
       "          (o_proj): Linear(in_features=896, out_features=896, bias=False)\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (up_proj): Linear(in_features=896, out_features=4864, bias=False)\n",
       "          (down_proj): Linear(in_features=4864, out_features=896, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "        (post_attention_layernorm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm((896,), eps=1e-06)\n",
       "    (rotary_emb): Qwen2RotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=896, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from collections import Counter\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "from metrics import repetition_score, token_diversity_score\n",
    "\n",
    "device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "model_id = \"Qwen/Qwen2.5-0.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Tracking Token Frequencies\n",
    "First, we need a way to count how often a token has appeared in our current generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token Counts for: A cat is a cat is a\n",
      "'A': 1\n",
      "' cat': 2\n",
      "' is': 2\n",
      "' a': 2\n"
     ]
    }
   ],
   "source": [
    "def get_token_counts(input_ids):\n",
    "    # input_ids is shape (1, seq_length)\n",
    "    sequence = input_ids[0].tolist()\n",
    "    return Counter(sequence)\n",
    "\n",
    "test_prompt = \"A cat is a cat is a\"\n",
    "test_ids = tokenizer(test_prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "counts = get_token_counts(test_ids)\n",
    "print(\"Token Counts for:\", test_prompt)\n",
    "for token_id, count in counts.items():\n",
    "    print(f\"{repr(tokenizer.decode(token_id))}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Applying the Penalties to Logits\n",
    "\n",
    "Now we write a function that takes our raw logits and our counts, and applies the penalties.\n",
    "\n",
    "`new_logit = logit - (count * frequency_penalty) - (presence_penalty)`\n",
    "\n",
    "Note: If the count is 0, the penalties do nothing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_repetition_penalties(logits, input_ids, freq_penalty, pres_penalty):\n",
    "    counts = get_token_counts(input_ids)\n",
    "    \n",
    "    # Create a copy so we don't modify the original\n",
    "    penalized_logits = logits.clone()\n",
    "    \n",
    "    for token_id, count in counts.items():\n",
    "        if count > 0:\n",
    "            # Apply Presence Penalty (flat deduction if count >= 1)\n",
    "            penalized_logits[token_id] -= pres_penalty\n",
    "            \n",
    "            # Apply Frequency Penalty (deduction scaled by count)\n",
    "            penalized_logits[token_id] -= (count * freq_penalty)\n",
    "            \n",
    "    return penalized_logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generation with Penalties\n",
    "\n",
    "Let's put this into a final, robust generation loop. We'll include Temperature, but we'll stick to a greedy choice at the end so we can clearly see the penalties working without randomness muddying the waters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: 'A cat is a cat is a' (Freq_Pen=0.0, Pres_Pen=0.0)\n",
      "Generating:  cat is a cat is a cat is a cat is a cat is a cat is a cat is a cat is a cat is a cat is a\n",
      "\n",
      "Diagnostics - Diversity: 0.10 (higher=more unique), 3-Gram Repetition: 0.89 (higher=more loops)\n",
      "\n",
      "\n",
      "--- Now let's fix it with a Frequency Penalty ---\n",
      "Prompt: 'A cat is a cat is a' (Freq_Pen=0.5, Pres_Pen=0.0)\n",
      "Generating:  dog is a dog is a cat. What is the next sentence?\n",
      "The answer to this question is:\n",
      "A dog is a dog.<|endoftext|>Human:\n",
      "\n",
      "Diagnostics - Diversity: 0.67 (higher=more unique), 3-Gram Repetition: 0.11 (higher=more loops)\n",
      "\n",
      "\n",
      "--- Now let's try extreme Presence Penalty (force vocabulary exploration) ---\n",
      "Prompt: 'A cat is a cat is a' (Freq_Pen=0.0, Pres_Pen=2.5)\n",
      "Generating:  dog.  What type of thing does \"cat\" and \"dog\" have in common? Options: - (A) animal - (B)\n",
      "\n",
      "Diagnostics - Diversity: 0.83 (higher=more unique), 3-Gram Repetition: 0.00 (higher=more loops)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def penalty_generate(prompt, freq_pen=0.0, pres_pen=0.0, max_new_tokens=30):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "    \n",
    "    print(f\"Prompt: '{prompt}' (Freq_Pen={freq_pen}, Pres_Pen={pres_pen})\")\n",
    "    print(\"Generating: \", end=\"\")\n",
    "    \n",
    "    generated_token_ids = []\n",
    "    \n",
    "    for _ in range(max_new_tokens):\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids)\n",
    "            \n",
    "        logits = outputs.logits[0, -1, :]\n",
    "        \n",
    "        # 1. Apply Repetition Penalties BEFORE softamx/temperature\n",
    "        if freq_pen > 0 or pres_pen > 0:\n",
    "            logits = apply_repetition_penalties(logits, input_ids, freq_pen, pres_pen)\n",
    "            \n",
    "        # 2. Greedy choice for this demonstration\n",
    "        next_token_id = torch.argmax(logits).unsqueeze(0).unsqueeze(0)\n",
    "        \n",
    "        generated_token_ids.append(next_token_id.item())\n",
    "        next_word = tokenizer.decode(next_token_id[0])\n",
    "        print(next_word, end=\"\", flush=True)\n",
    "        \n",
    "        input_ids = torch.cat([input_ids, next_token_id], dim=-1)\n",
    "        \n",
    "    print(\"\\n\")\n",
    "    \n",
    "    # Print diagnostics using our metrics module\n",
    "    div_score = token_diversity_score(generated_token_ids)\n",
    "    rep_score = repetition_score(generated_token_ids, n=3)\n",
    "    print(f\"Diagnostics - Diversity: {div_score:.2f} (higher=more unique), 3-Gram Repetition: {rep_score:.2f} (higher=more loops)\\n\")\n",
    "    \n",
    "    return tokenizer.decode(input_ids[0])\n",
    "\n",
    "# Let's feed it a prompt guaranteed to cause a loop in greedy decoding\n",
    "loop_prompt = \"A cat is a cat is a\"\n",
    "generator_tokens = penalty_generate(loop_prompt, freq_pen=0.0, pres_pen=0.0)\n",
    "\n",
    "print(\"\\n--- Now let's fix it with a Frequency Penalty ---\")\n",
    "generator_tokens = penalty_generate(loop_prompt, freq_pen=0.5, pres_pen=0.0)\n",
    "\n",
    "print(\"\\n--- Now let's try extreme Presence Penalty (force vocabulary exploration) ---\")\n",
    "generator_tokens = penalty_generate(loop_prompt, freq_pen=0.0, pres_pen=2.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¬ Experimentation Ideas\n",
    "\n",
    "1. **Feed a prompt that usually causes looping:** (e.g., \"Repeat the word cat forever: cat cat cat\").\n",
    "   * *Incrementally increase frequency penalty: 0.0 -> 0.5 -> 1.0 -> 2.0. Watch the diversity score rise.*\n",
    "2. **Compare the penalties implicitly vs explicitly:**\n",
    "   * *Frequency Penalty only: What does it output?*\n",
    "   * *Presence Penalty only: Does it sound different from Frequency Penalty?*\n",
    "   * *Both combined: Is it too chaotic?*\n",
    "3. **Measure how token diversity changes:** (unique tokens / total tokens) using `metrics.token_diversity_score`.\n",
    "   * *Does higher penalty guarantee higher diversity?*\n",
    "4. **Observe whether penalties reduce coherence at high values:**\n",
    "   * *If you set `freq_pen=5.0`, does the model start outputting completely random nonsense just to avoid using words it has already used?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Experiment 1: Incrementally increasing frequency penalty ===\n",
      "\n",
      "Prompt: Repeat the word cat forever: cat cat cat\n",
      "\n",
      "--- Freq Penalty: 0.0 ---\n",
      "Prompt: 'Repeat the word cat forever: cat cat cat' (Freq_Pen=0.0, Pres_Pen=0.0)\n",
      "Generating:  cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat cat\n",
      "\n",
      "Diagnostics - Diversity: 0.03 (higher=more unique), 3-Gram Repetition: 0.97 (higher=more loops)\n",
      "\n",
      "\n",
      "--- Freq Penalty: 0.5 ---\n",
      "Prompt: 'Repeat the word cat forever: cat cat cat' (Freq_Pen=0.5, Pres_Pen=0.0)\n",
      "Generating: \n",
      "cat cat cat\n",
      "\n",
      "Repeat the word \"cat\" forever: cat cat cat\n",
      "\n",
      "Repeat the word \"cat\" forever: cat cat cat\n",
      "\n",
      "Repeat the word \"cat\" forever: cat<|endoftext|>Human\n",
      "\n",
      "Diagnostics - Diversity: 0.33 (higher=more unique), 3-Gram Repetition: 0.58 (higher=more loops)\n",
      "\n",
      "\n",
      "--- Freq Penalty: 1.0 ---\n",
      "Prompt: 'Repeat the word cat forever: cat cat cat' (Freq_Pen=1.0, Pres_Pen=0.0)\n",
      "Generating: \n",
      "cat\n",
      "\n",
      "Repeat the word \"cat\" forever: cat, cat, cat\n",
      "cat\n",
      "\n",
      "Repeat the word \"cat\" forever: cattt cattt cattt\n",
      "cattt\n",
      "\n",
      "Diagnostics - Diversity: 0.40 (higher=more unique), 3-Gram Repetition: 0.37 (higher=more loops)\n",
      "\n",
      "\n",
      "--- Freq Penalty: 2.0 ---\n",
      "Prompt: 'Repeat the word cat forever: cat cat cat' (Freq_Pen=2.0, Pres_Pen=0.0)\n",
      "Generating: \n",
      "cat\n",
      "\n",
      "Repeat the word \"cat\" forever: cattcattcatt<|endoftext|>Human: You are given a sentence in Italian. Your job is to translate the Italian sentence into English.\n",
      "Q\n",
      "\n",
      "Diagnostics - Diversity: 0.80 (higher=more unique), 3-Gram Repetition: 0.03 (higher=more loops)\n",
      "\n",
      "\n",
      "=== Experiment 2 & 3: Implicit vs Explicit Penalties & Diversity Score ===\n",
      "\n",
      "Prompt: A beautiful sunset over the mountains is\n",
      "\n",
      "--- Frequency Penalty Only (1.5) ---\n",
      "Prompt: 'A beautiful sunset over the mountains is' (Freq_Pen=1.5, Pres_Pen=0.0)\n",
      "Generating:  a perfect example of how nature can be so beautiful and peaceful. The colors are vibrant, the light is warm, and the view is breathtaking.\n",
      "The sun sets in shades of orange, pink, and\n",
      "\n",
      "Diagnostics - Diversity: 0.80 (higher=more unique), 3-Gram Repetition: 0.00 (higher=more loops)\n",
      "\n",
      "\n",
      "--- Presence Penalty Only (1.5) ---\n",
      "Prompt: 'A beautiful sunset over the mountains is' (Freq_Pen=0.0, Pres_Pen=1.5)\n",
      "Generating:  a perfect example of how nature can be so beautiful and peaceful. The colors are vibrant, the light is warm, and the view is breathtaking.\n",
      "The sun sets in the distance, casting a golden glow\n",
      "\n",
      "Diagnostics - Diversity: 0.82 (higher=more unique), 3-Gram Repetition: 0.00 (higher=more loops)\n",
      "\n",
      "\n",
      "--- Both Combined (1.5 / 1.5) ---\n",
      "Prompt: 'A beautiful sunset over the mountains is' (Freq_Pen=1.5, Pres_Pen=1.5)\n",
      "Generating:  a perfect example of how nature can be so breathtakingly stunning. The colors and shapes are truly mesmerizing, with shades of reds, oranges, yellows and blues that create an awe-inspiring\n",
      "\n",
      "Diagnostics - Diversity: 0.90 (higher=more unique), 3-Gram Repetition: 0.00 (higher=more loops)\n",
      "\n",
      "\n",
      "=== Experiment 4: Extreme Penalties (Reduce Coherence) ===\n",
      "Watch the model start outputting complete nonsense or obscure tokens just to avoid repeating itself!\n",
      "Prompt: 'A beautiful sunset over the mountains is' (Freq_Pen=5.0, Pres_Pen=5.0)\n",
      "Generating:  a perfect example of how nature can be so breathtakingly stunning. The colors and shapes are truly mesmerizing, with shades ranging from deep reds to warm oranges.\n",
      "The sun sets in hues that range\n",
      "\n",
      "Diagnostics - Diversity: 1.00 (higher=more unique), 3-Gram Repetition: 0.00 (higher=more loops)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A beautiful sunset over the mountains is a perfect example of how nature can be so breathtakingly stunning. The colors and shapes are truly mesmerizing, with shades ranging from deep reds to warm oranges.\\nThe sun sets in hues that range'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "from metrics import token_diversity_score\n",
    "import torch\n",
    "\n",
    "# Ensure local setup works if run independently\n",
    "# device = 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# model_id = \"Qwen/Qwen2.5-0.5B\"\n",
    "# from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "\n",
    "print(\"=== Experiment 1: Incrementally increasing frequency penalty ===\")\n",
    "loop_prompt = \"Repeat the word cat forever: cat cat cat\"\n",
    "print(f\"\\nPrompt: {loop_prompt}\")\n",
    "\n",
    "for freq in [0.0, 0.5, 1.0, 2.0]:\n",
    "    # We reuse the penalty_generate from above. \n",
    "    print(f\"\\n--- Freq Penalty: {freq} ---\")\n",
    "    penalty_generate(loop_prompt, freq_pen=freq, pres_pen=0.0, max_new_tokens=40)\n",
    "\n",
    "print(\"\\n=== Experiment 2 & 3: Implicit vs Explicit Penalties & Diversity Score ===\")\n",
    "test_prompt = \"A beautiful sunset over the mountains is\"\n",
    "print(f\"\\nPrompt: {test_prompt}\")\n",
    "\n",
    "print(\"\\n--- Frequency Penalty Only (1.5) ---\")\n",
    "penalty_generate(test_prompt, freq_pen=1.5, pres_pen=0.0, max_new_tokens=40)\n",
    "\n",
    "print(\"\\n--- Presence Penalty Only (1.5) ---\")\n",
    "penalty_generate(test_prompt, freq_pen=0.0, pres_pen=1.5, max_new_tokens=40)\n",
    "\n",
    "print(\"\\n--- Both Combined (1.5 / 1.5) ---\")\n",
    "penalty_generate(test_prompt, freq_pen=1.5, pres_pen=1.5, max_new_tokens=40)\n",
    "\n",
    "print(\"\\n=== Experiment 4: Extreme Penalties (Reduce Coherence) ===\")\n",
    "print(\"Watch the model start outputting complete nonsense or obscure tokens just to avoid repeating itself!\")\n",
    "penalty_generate(test_prompt, freq_pen=5.0, pres_pen=5.0, max_new_tokens=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
